{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72c21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 1: Setup and Imports =====\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF\n",
    "import google.generativeai as genai\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play, save\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "INPUT_DIR = DATA_DIR / \"input\"\n",
    "OUTPUT_DIR = DATA_DIR / \"output\"\n",
    "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [DATA_DIR, INPUT_DIR, OUTPUT_DIR, CONFIG_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f525c52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded!\n",
      "Target podcast duration: 10 minutes\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 2: Configuration Management =====\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from YAML file\"\"\"\n",
    "    config_path = CONFIG_DIR / \"config.yaml\"\n",
    "    \n",
    "    # Default config if file doesn't exist\n",
    "    default_config = {\n",
    "        'pdf': {'max_pages': 50},\n",
    "        'gemini': {\n",
    "            'model': 'gemini-1.5-flash',\n",
    "            'temperature': 0.7,\n",
    "            'max_output_tokens': 8192\n",
    "        },\n",
    "        'podcast': {\n",
    "            'target_duration_minutes': 10,\n",
    "            'style': 'conversational',\n",
    "            'tone': 'engaging'\n",
    "        },\n",
    "        'elevenlabs': {\n",
    "            'model': 'eleven_monolingual_v1',\n",
    "            'voice_settings': {\n",
    "                'stability': 0.75,\n",
    "                'similarity_boost': 0.85,\n",
    "                'style': 0.0,\n",
    "                'use_speaker_boost': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    else:\n",
    "        config = default_config\n",
    "        # Save default config\n",
    "        with open(config_path, 'w') as f:\n",
    "            yaml.dump(config, f, default_flow_style=False)\n",
    "    \n",
    "    return config\n",
    "\n",
    "config = load_config()\n",
    "print(\"‚úÖ Configuration loaded!\")\n",
    "print(f\"Target podcast duration: {config['podcast']['target_duration_minutes']} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79574605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API: API test successful\n",
      "‚úÖ ElevenLabs API: Found 19 voices\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 3: API Setup and Validation =====\n",
    "def setup_apis():\n",
    "    \"\"\"Setup and validate API connections\"\"\"\n",
    "    \n",
    "    # Setup Gemini\n",
    "    gemini_key = os.getenv('GEMINI_API_KEY')\n",
    "    if not gemini_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in environment variables\")\n",
    "    \n",
    "    genai.configure(api_key=gemini_key)\n",
    "    \n",
    "    # Setup ElevenLabs\n",
    "    elevenlabs_key = os.getenv('ELEVENLABS_API_KEY')\n",
    "    if not elevenlabs_key:\n",
    "        raise ValueError(\"ELEVENLABS_API_KEY not found in environment variables\")\n",
    "    \n",
    "    # Initialize ElevenLabs client\n",
    "    global eleven_client\n",
    "    eleven_client = ElevenLabs(api_key=elevenlabs_key)\n",
    "    \n",
    "    return True\n",
    "\n",
    "def test_apis():\n",
    "    \"\"\"Test API connections\"\"\"\n",
    "    try:\n",
    "        # Test Gemini\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        response = model.generate_content(\"Say 'API test successful'\")\n",
    "        print(f\"‚úÖ Gemini API: {response.text.strip()}\")\n",
    "        \n",
    "        # Test ElevenLabs (get available voices)\n",
    "        available_voices = eleven_client.voices.get_all()\n",
    "        print(f\"‚úÖ ElevenLabs API: Found {len(available_voices.voices)} voices\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API Test Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Setup APIs\n",
    "setup_apis()\n",
    "api_status = test_apis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ce64c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF processor initialized!\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 4: PDF Text Extraction =====\n",
    "class PDFProcessor:\n",
    "    def __init__(self, max_pages: int = 50):\n",
    "        self.max_pages = max_pages\n",
    "    \n",
    "    def extract_text_pymupdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text using PyMuPDF (better for complex PDFs)\"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        \n",
    "        pages_to_process = min(len(doc), self.max_pages)\n",
    "        \n",
    "        for page_num in tqdm(range(pages_to_process), desc=\"Extracting PDF text\"):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "            text += \"\\n\\n\"\n",
    "        \n",
    "        doc.close()\n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_text_pypdf2(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text using PyPDF2 (fallback method)\"\"\"\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            \n",
    "            pages_to_process = min(len(pdf_reader.pages), self.max_pages)\n",
    "            \n",
    "            for page_num in tqdm(range(pages_to_process), desc=\"Extracting PDF text\"):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "                text += \"\\n\\n\"\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_text(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF using the best available method\"\"\"\n",
    "        try:\n",
    "            # Try PyMuPDF first (better quality)\n",
    "            text = self.extract_text_pymupdf(pdf_path)\n",
    "            if len(text.strip()) < 100:  # If extraction failed\n",
    "                raise Exception(\"PyMuPDF extraction insufficient\")\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"PyMuPDF failed ({e}), falling back to PyPDF2...\")\n",
    "            return self.extract_text_pypdf2(pdf_path)\n",
    "\n",
    "# Initialize PDF processor\n",
    "pdf_processor = PDFProcessor(max_pages=config['pdf']['max_pages'])\n",
    "print(\"‚úÖ PDF processor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f89b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Podcast script generator initialized!\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 5: Gemini-Powered Script Generation =====\n",
    "class PodcastScriptGenerator:\n",
    "    def __init__(self, model_name: str = \"gemini-1.5-flash\"):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "        self.config = config['gemini']\n",
    "        self.podcast_config = config['podcast']\n",
    "    \n",
    "    def analyze_text_length(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze the input text to understand its scope\"\"\"\n",
    "        word_count = len(text.split())\n",
    "        char_count = len(text)\n",
    "        \n",
    "        # Estimate reading time (average 200 words per minute)\n",
    "        reading_time_minutes = word_count / 200\n",
    "        \n",
    "        return {\n",
    "            'word_count': word_count,\n",
    "            'char_count': char_count,\n",
    "            'estimated_reading_time': reading_time_minutes,\n",
    "            'pages_estimate': word_count / 250  # ~250 words per page\n",
    "        }\n",
    "    \n",
    "    def create_podcast_prompt(self, text: str, analysis: Dict[str, Any]) -> str:\n",
    "        \"\"\"Create a comprehensive prompt for podcast script generation\"\"\"\n",
    "        \n",
    "        target_duration = self.podcast_config['target_duration_minutes']\n",
    "        style = self.podcast_config['style']\n",
    "        tone = self.podcast_config['tone']\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert podcast scriptwriter. Convert the following research paper into an engaging {target_duration}-minute podcast script.\n",
    "\n",
    "**REQUIREMENTS:**\n",
    "- Create a {style} and {tone} podcast script\n",
    "- Target duration: {target_duration} minutes (approximately {target_duration * 150} words)\n",
    "- Structure: Introduction, Main Content (2-3 key points), Conclusion\n",
    "- Use natural speech patterns, pauses, and transitions\n",
    "- Make complex concepts accessible to general audience\n",
    "- Include engaging hooks and smooth transitions\n",
    "\n",
    "**INPUT TEXT ANALYSIS:**\n",
    "- Word count: {analysis['word_count']}\n",
    "- Estimated reading time: {analysis['estimated_reading_time']:.1f} minutes\n",
    "- Content scope: {analysis['pages_estimate']:.1f} pages\n",
    "\n",
    "**SCRIPT FORMAT:**\n",
    "Structure your response as a natural podcast script with:\n",
    "1. **INTRO** (30 seconds): Hook the audience with the paper's significance\n",
    "2. **MAIN CONTENT** (8-9 minutes): Break down key findings into digestible segments\n",
    "3. **CONCLUSION** (30 seconds): Summarize impact and future implications\n",
    "\n",
    "**TONE GUIDELINES:**\n",
    "- Conversational and accessible\n",
    "- Enthusiastic about the research\n",
    "- Use analogies and examples\n",
    "- Smooth transitions between topics\n",
    "- Natural speaking rhythm\n",
    "\n",
    "**RESEARCH PAPER TEXT:**\n",
    "{text}\n",
    "\n",
    "Generate the podcast script now:\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def generate_script(self, text: str) -> str:\n",
    "        \"\"\"Generate podcast script from research paper text\"\"\"\n",
    "        \n",
    "        print(\"üîç Analyzing text...\")\n",
    "        analysis = self.analyze_text_length(text)\n",
    "        \n",
    "        print(f\"üìä Text Analysis:\")\n",
    "        print(f\"   - Words: {analysis['word_count']:,}\")\n",
    "        print(f\"   - Characters: {analysis['char_count']:,}\")\n",
    "        print(f\"   - Estimated reading time: {analysis['estimated_reading_time']:.1f} minutes\")\n",
    "        \n",
    "        print(\"ü§ñ Generating podcast script with Gemini...\")\n",
    "        prompt = self.create_podcast_prompt(text, analysis)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=self.config['temperature'],\n",
    "                    max_output_tokens=self.config['max_output_tokens']\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            script = response.text\n",
    "            \n",
    "            # Basic validation\n",
    "            if len(script) < 500:\n",
    "                raise Exception(\"Generated script too short\")\n",
    "            \n",
    "            print(f\"‚úÖ Script generated! Length: {len(script.split())} words\")\n",
    "            return script\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Script generation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize script generator\n",
    "script_generator = PodcastScriptGenerator(config['gemini']['model'])\n",
    "print(\"‚úÖ Podcast script generator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e249363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Audio generator initialized!\n",
      "üì¢ Available voices: 19\n",
      "   - Aria\n",
      "   - Sarah\n",
      "   - Laura\n",
      "   - Charlie\n",
      "   - George\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 6: ElevenLabs Text-to-Speech (FIXED WITH TIMEOUT & CHUNKING) =====\n",
    "class AudioGenerator:\n",
    "    def __init__(self):\n",
    "        self.config = config['elevenlabs']\n",
    "        self.voice_id = os.getenv('ELEVENLABS_VOICE_ID', None)\n",
    "        self.client = eleven_client\n",
    "        # Set longer timeout for audio generation\n",
    "        self.client.timeout = 300  # 5 minutes\n",
    "    \n",
    "    def get_available_voices(self):\n",
    "        \"\"\"Get list of available voices\"\"\"\n",
    "        try:\n",
    "            voices_response = self.client.voices.get_all()\n",
    "            return [(voice.voice_id, voice.name) for voice in voices_response.voices]\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting voices: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def select_best_voice(self):\n",
    "        \"\"\"Select the best voice for podcast narration\"\"\"\n",
    "        available_voices = self.get_available_voices()\n",
    "        \n",
    "        if not available_voices:\n",
    "            return None\n",
    "        \n",
    "        # If specific voice ID is set, use it\n",
    "        if self.voice_id:\n",
    "            for voice_id, name in available_voices:\n",
    "                if voice_id == self.voice_id:\n",
    "                    print(f\"üé§ Using specified voice: {name}\")\n",
    "                    return voice_id\n",
    "        \n",
    "        # Prefer specific voices for podcast narration (if available)\n",
    "        preferred_names = ['Rachel', 'Adam', 'Antoni', 'Arnold', 'Josh', 'Sam', 'Daniel', 'Lily']\n",
    "        \n",
    "        for voice_id, name in available_voices:\n",
    "            if name in preferred_names:\n",
    "                print(f\"üé§ Selected voice: {name}\")\n",
    "                return voice_id\n",
    "        \n",
    "        # Use first available voice as fallback\n",
    "        voice_id, name = available_voices[0]\n",
    "        print(f\"üé§ Using voice: {name}\")\n",
    "        return voice_id\n",
    "    \n",
    "    def chunk_text(self, text: str, max_chars: int = 2500) -> list:\n",
    "        \"\"\"Split text into smaller chunks for processing\"\"\"\n",
    "        chunks = []\n",
    "        sentences = text.split('. ')\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # If adding this sentence would exceed the limit, save current chunk\n",
    "            if len(current_chunk) + len(sentence) + 2 > max_chars and current_chunk:\n",
    "                chunks.append(current_chunk.strip() + '.')\n",
    "                current_chunk = sentence\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    current_chunk += '. ' + sentence\n",
    "                else:\n",
    "                    current_chunk = sentence\n",
    "        \n",
    "        # Add the last chunk\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def generate_audio_chunk(self, text: str, voice_id: str, chunk_num: int) -> bytes:\n",
    "        \"\"\"Generate audio for a single text chunk\"\"\"\n",
    "        print(f\"   üîÑ Processing chunk {chunk_num}: {len(text)} characters\")\n",
    "        \n",
    "        try:\n",
    "            # Generate audio with retry logic\n",
    "            max_retries = 3\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    audio = self.client.text_to_speech.convert(\n",
    "                        voice_id=voice_id,\n",
    "                        text=text,\n",
    "                        model_id=self.config['model'],\n",
    "                        voice_settings={\n",
    "                            \"stability\": self.config['voice_settings']['stability'],\n",
    "                            \"similarity_boost\": self.config['voice_settings']['similarity_boost'],\n",
    "                            \"style\": self.config['voice_settings']['style'],\n",
    "                            \"use_speaker_boost\": self.config['voice_settings']['use_speaker_boost']\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    # Collect all audio data\n",
    "                    audio_data = b\"\"\n",
    "                    for chunk in audio:\n",
    "                        audio_data += chunk\n",
    "                    \n",
    "                    return audio_data\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"   ‚ö†Ô∏è Chunk {chunk_num} attempt {attempt + 1} failed, retrying...\")\n",
    "                        time.sleep(2 ** attempt)  # Exponential backoff\n",
    "                    else:\n",
    "                        raise e\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to generate chunk {chunk_num}: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def generate_audio(self, text: str, output_path: str) -> bool:\n",
    "        \"\"\"Generate audio from text using ElevenLabs - IMPROVED WITH CHUNKING\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Select voice\n",
    "            voice_id = self.select_best_voice()\n",
    "            if not voice_id:\n",
    "                raise Exception(\"No voices available\")\n",
    "            \n",
    "            print(\"üéµ Generating audio with ElevenLabs...\")\n",
    "            print(f\"   - Text length: {len(text)} characters\")\n",
    "            print(f\"   - Estimated audio duration: {len(text.split()) / 150:.1f} minutes\")\n",
    "            \n",
    "            # Check if text needs to be chunked (over 2500 characters)\n",
    "            if len(text) > 2500:\n",
    "                print(\"   üìù Text is long, splitting into chunks...\")\n",
    "                chunks = self.chunk_text(text, max_chars=2500)\n",
    "                print(f\"   üì¶ Split into {len(chunks)} chunks\")\n",
    "                \n",
    "                # Generate audio for each chunk\n",
    "                all_audio_data = b\"\"\n",
    "                \n",
    "                for i, chunk in enumerate(chunks, 1):\n",
    "                    chunk_audio = self.generate_audio_chunk(chunk, voice_id, i)\n",
    "                    all_audio_data += chunk_audio\n",
    "                    \n",
    "                    # Small delay between chunks to avoid rate limiting\n",
    "                    if i < len(chunks):\n",
    "                        time.sleep(1)\n",
    "                \n",
    "                # Save combined audio\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    f.write(all_audio_data)\n",
    "                    \n",
    "            else:\n",
    "                # Single chunk processing\n",
    "                print(\"   üìù Processing as single chunk...\")\n",
    "                audio = self.client.text_to_speech.convert(\n",
    "                    voice_id=voice_id,\n",
    "                    text=text,\n",
    "                    model_id=self.config['model'],\n",
    "                    voice_settings={\n",
    "                        \"stability\": self.config['voice_settings']['stability'],\n",
    "                        \"similarity_boost\": self.config['voice_settings']['similarity_boost'],\n",
    "                        \"style\": self.config['voice_settings']['style'],\n",
    "                        \"use_speaker_boost\": self.config['voice_settings']['use_speaker_boost']\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Save audio file\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    for chunk in audio:\n",
    "                        f.write(chunk)\n",
    "            \n",
    "            print(f\"‚úÖ Audio saved to: {output_path}\")\n",
    "            \n",
    "            # Verify file was created and has content\n",
    "            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
    "                file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
    "                print(f\"   üìÅ File size: {file_size:.2f} MB\")\n",
    "                return True\n",
    "            else:\n",
    "                raise Exception(\"Audio file was not created or is empty\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Audio generation failed: {e}\")\n",
    "            # Print more detailed error info\n",
    "            import traceback\n",
    "            print(f\"Full error: {traceback.format_exc()}\")\n",
    "            return False\n",
    "\n",
    "# Initialize audio generator\n",
    "audio_generator = AudioGenerator()\n",
    "print(\"‚úÖ Audio generator initialized!\")\n",
    "\n",
    "# Display available voices\n",
    "voices_list = audio_generator.get_available_voices()\n",
    "print(f\"üì¢ Available voices: {len(voices_list)}\")\n",
    "for voice_id, name in voices_list[:5]:  # Show first 5\n",
    "    print(f\"   - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c10ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline function ready!\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 7: Main Pipeline Function =====\n",
    "def run_pdf_to_podcast_pipeline(pdf_path: str, output_name: str = \"podcast\"):\n",
    "    \"\"\"Main pipeline to convert PDF to podcast\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting PDF to Podcast Pipeline\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Validate input\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "    \n",
    "    # Define output paths\n",
    "    text_output = OUTPUT_DIR / f\"{output_name}_extracted.txt\"\n",
    "    script_output = OUTPUT_DIR / f\"{output_name}_script.txt\"\n",
    "    audio_output = OUTPUT_DIR / f\"{output_name}.mp3\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract text from PDF\n",
    "        print(\"\\nüìÑ Step 1: Extracting text from PDF...\")\n",
    "        extracted_text = pdf_processor.extract_text(pdf_path)\n",
    "        \n",
    "        # Save extracted text\n",
    "        with open(text_output, 'w', encoding='utf-8') as f:\n",
    "            f.write(extracted_text)\n",
    "        \n",
    "        print(f\"‚úÖ Text extracted: {len(extracted_text.split())} words\")\n",
    "        \n",
    "        # Step 2: Generate podcast script\n",
    "        print(\"\\nü§ñ Step 2: Generating podcast script...\")\n",
    "        podcast_script = script_generator.generate_script(extracted_text)\n",
    "        \n",
    "        # Save script\n",
    "        with open(script_output, 'w', encoding='utf-8') as f:\n",
    "            f.write(podcast_script)\n",
    "        \n",
    "        print(f\"‚úÖ Script generated: {len(podcast_script.split())} words\")\n",
    "        \n",
    "        # Step 3: Generate audio\n",
    "        print(\"\\nüéµ Step 3: Converting script to audio...\")\n",
    "        success = audio_generator.generate_audio(podcast_script, str(audio_output))\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\nüéâ Pipeline completed successfully!\")\n",
    "            print(f\"üìÅ Output files:\")\n",
    "            print(f\"   - Extracted text: {text_output}\")\n",
    "            print(f\"   - Podcast script: {script_output}\")\n",
    "            print(f\"   - Audio file: {audio_output}\")\n",
    "            \n",
    "            return {\n",
    "                'text_file': text_output,\n",
    "                'script_file': script_output,\n",
    "                'audio_file': audio_output,\n",
    "                'success': True\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\"Audio generation failed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Pipeline failed: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "print(\"‚úÖ Pipeline function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd17afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã To run the pipeline:\n",
      "1. Download a PDF file to the 'data/input/' folder\n",
      "2. Update the pdf_path variable below\n",
      "3. Run the pipeline\n",
      "\n",
      "Example:\n",
      "pdf_path = INPUT_DIR / 'your_paper.pdf'\n",
      "result = run_pdf_to_podcast_pipeline(pdf_path, 'my_podcast')\n",
      "üöÄ Starting PDF to Podcast Pipeline\n",
      "==================================================\n",
      "\n",
      "üìÑ Step 1: Extracting text from PDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting PDF text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 107.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text extracted: 6095 words\n",
      "\n",
      "ü§ñ Step 2: Generating podcast script...\n",
      "üîç Analyzing text...\n",
      "üìä Text Analysis:\n",
      "   - Words: 6,095\n",
      "   - Characters: 39,525\n",
      "   - Estimated reading time: 30.5 minutes\n",
      "ü§ñ Generating podcast script with Gemini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Script generated! Length: 651 words\n",
      "‚úÖ Script generated: 651 words\n",
      "\n",
      "üéµ Step 3: Converting script to audio...\n",
      "üé§ Selected voice: Daniel\n",
      "üéµ Generating audio with ElevenLabs...\n",
      "   - Text length: 4591 characters\n",
      "   - Estimated audio duration: 4.3 minutes\n",
      "   üìù Text is long, splitting into chunks...\n",
      "   üì¶ Split into 2 chunks\n",
      "   üîÑ Processing chunk 1: 2422 characters\n",
      "   üîÑ Processing chunk 2: 2166 characters\n",
      "‚úÖ Audio saved to: c:\\Users\\Mohammed Kayser\\OneDrive\\Desktop\\My_Portfolio\\Projects\\PDF_2_PODCAST_CLAUDE\\notebooks\\data\\output\\transformer_podcast.mp3\n",
      "   üìÅ File size: 4.69 MB\n",
      "\n",
      "üéâ Pipeline completed successfully!\n",
      "üìÅ Output files:\n",
      "   - Extracted text: c:\\Users\\Mohammed Kayser\\OneDrive\\Desktop\\My_Portfolio\\Projects\\PDF_2_PODCAST_CLAUDE\\notebooks\\data\\output\\transformer_podcast_extracted.txt\n",
      "   - Podcast script: c:\\Users\\Mohammed Kayser\\OneDrive\\Desktop\\My_Portfolio\\Projects\\PDF_2_PODCAST_CLAUDE\\notebooks\\data\\output\\transformer_podcast_script.txt\n",
      "   - Audio file: c:\\Users\\Mohammed Kayser\\OneDrive\\Desktop\\My_Portfolio\\Projects\\PDF_2_PODCAST_CLAUDE\\notebooks\\data\\output\\transformer_podcast.mp3\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 8: Execute Pipeline (MODIFY THIS PART) =====\n",
    "# Example: Process the Transformer paper\n",
    "print(\"üìã To run the pipeline:\")\n",
    "print(\"1. Download a PDF file to the 'data/input/' folder\")\n",
    "print(\"2. Update the pdf_path variable below\")\n",
    "print(\"3. Run the pipeline\")\n",
    "print()\n",
    "print(\"Example:\")\n",
    "print(f\"pdf_path = INPUT_DIR / 'your_paper.pdf'\")\n",
    "print(f\"result = run_pdf_to_podcast_pipeline(pdf_path, 'my_podcast')\")\n",
    "\n",
    "# UNCOMMENT AND MODIFY THESE LINES TO RUN WITH YOUR PDF:\n",
    "pdf_path = INPUT_DIR / \"transformer_paper.pdf\"  # Replace with your PDF filename\n",
    "result = run_pdf_to_podcast_pipeline(pdf_path, \"transformer_podcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c90eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b1c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75040ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0872f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59d573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52beb62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
